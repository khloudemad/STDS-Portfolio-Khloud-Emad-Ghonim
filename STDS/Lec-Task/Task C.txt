# Lifecycle of a Single Smart Meter Record

This step-by-step explanation traces one individual reading from ingestion to archival.

1. *Upload to Raw Storage*  
   The smart meter sends a reading (part of a CSV batch) which is automatically uploaded to the raw object storage bucket (landing zone).

2. *Triggering the Transformation Process*  
   The file upload event automatically triggers the serverless extraction function, which parses the CSV and processes records individually or in micro-batches.

3. *Data Cleaning and Validation*  
   The record undergoes sequential transformation:  
   - Unit standardization (Rule 1).  
   - Missing value handling (Rule 2).  
   - Outlier and validity checks (Rule 3).  
   - Faulty meter logic (Rule 4).  
   - Timestamp normalization and deduplication (Rule 5).  
   If any validation fails, the record is sent to an error queue with up to 3 automatic retries. Persistent failures go to a dead-letter queue with admin alert.

4. *Load to Structured Storage*  
   Upon successful transformation and validation, the cleaned record is inserted into a relational database (e.g., tabular schema with meter_id, timestamp, kW, flags). This enables easy querying, manual validation, and operational dashboards.

5. *Conversion and Archival in Parquet Format*  
   After successful load (or in parallel via batch), transformed records are aggregated and converted to Parquet (columnar format) and stored in an analytics-optimized long-term archive. This supports efficient historical queries using tools like Athena, Spark, or BigQuery.

6. *Success vs. Failure Handling*  
   - *Success Path*: Full lifecycle completes automatically; success logged in monitoring system.  
   - *Failure Path*: After max retries, record remains in raw storage, flagged in dead-letter queue, and alerts sent for manual intervention. Original raw data preserved for reproducibility.

*Outcome*: Each record emerges as clean, standardized, flagged (where needed), and available in both query-friendly and analytics-optimized formatsâ€”ready for peak analysis, forecasting models, and operational insights.
